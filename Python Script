
###### Preprocessing ######

### Preprocess 1 ###

import string
import re
from nltk.corpus import stopwords
from stemming.porter2 import stem
import networkx 
import numpy as np
import networkx as nx
import seaborn as sns
import nltk

nltk.download('stopwords')

#open file to read Amazon product metadata from http://snap.stanford.edu/data/amazon-meta.html
fhr = open ('amazon-meta.txt', 'r', encoding='utf-8', errors= 'ignore')



### Preprocess 2 ###

(Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = ("", "", "", "", "", "", 0, 0, 0.0, 0, 0.0)

for line in fhr:
    line = line.strip()
    # a pduct block started
    if(line.startswith("Id")):
        Id = line[3:].strip()
    elif(line.startswith("ASIN")):
        ASIN = line[5:].strip()
    elif(line.startswith("title")):
        Title = line[6:].strip()
        Title = ' '.join(Title.split())
        #TitleTfidf = Title.lower()
        #TitleTfidf = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ',TitleTfidf)
        #TitleTfidf = ' '.join(set(TitleTfidf.split())-set(stopwords.words("english")))
        #TitleTfidf = ' '.join(stem(word) for word in TitleTfidf.split())
    elif(line.startswith("group")):
        Group = line[6:].strip()
    elif(line.startswith("salesrank")):
        SalesRank = line[10:].strip()
    elif(line.startswith("similar")):
        ls = line.split()
        Copurchased = ' '.join([c for c in ls[2:]])
    elif(line.startswith("categories")):
        ls = line.split()
        Categories = ' '.join((fhr.readline()).lower() for i in range(int(ls[1].strip())))
        Categories = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ',Categories)
        Categories = ' '.join(set(Categories.split())-set(stopwords.words("english")))
        Categories = ' '.join(stem(word) for word in Categories.split())
    elif(line.startswith("reviews")):
        ls = line.split()
        TotalReviews = ls[2].strip()
        AvgRating = ls[7].strip()
    # a product block eneded
    # write out fields to amazonProducts Dictionary
    elif (line==""):
        try:
            MetaData = {}
            if (ASIN != ""):
                amazonProducts[ASIN] = MetaData
            MetaData['Id'] = Id
            MetaData['Title'] = Title
            MetaData['Categories'] = ' '.join(set(Categories.split()))
            MetaData['Group'] = Group
            MetaData['Copurchased'] = Copurchased
            MetaData['SalesRank'] = int(SalesRank)
            MetaData['TotalReviews'] = int(TotalReviews)
            MetaData['AvgRating'] = float(AvgRating)
            MetaData['DegreeCentrality'] = DegreeCentrality
            MetaData['ClusteringCoeff'] = ClusteringCoeff
        except NameError:
            continue
        (Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating, DegreeCentrality, ClusteringCoeff) = ("", "", "", "", "", "", 0, 0, 0.0, 0, 0.0)
fhr.close
        


### Preprocess 3 ###

#create book specific dictionary exclusively for books
amazonBooks = {}
for asin,metadata in amazonProducts.items():
    if (metadata['Group']=='Book'):
        amazonBooks[asin]=amazonProducts[asin]
        
#remove any copurchased items from copurchase list. If we don't have metadata associated with it
for asin, metadata in amazonBooks.items():
    amazonBooks[asin]['Copurchased']= ' '.join([cp for cp in metadata['Copurchased'].split() if cp in amazonBooks.keys()])
    


### Preprocess 4 ###         
                                   
#create a product copurchase graph for analysis
#the graph nodes are product ASINs, the graph edge exists if two products were copurchased, with edge weight being a measure of category similarity between ASINs
copurchaseGraph = networkx.Graph()
for asin, metadata in amazonBooks.items():
    copurchaseGraph.add_node(asin)
    for a in metadata ['Copurchased'].split():
        copurchaseGraph.add_node(a.strip())
        similarity=0
        n1= set((amazonBooks[asin]['Categories']).split())
        n2= set ((amazonBooks[a]['Categories']).split())
        n1In2 = n1 & n2
        n1Un2 = n1 | n2
        if (len(n1Un2)) > 0:
            similarity = round (len(n1In2)/len(n1Un2), 2)
        copurchaseGraph.add_edge(asin, a.strip(), weight=similarity)


### Preprocess 5 ###         

dc = networkx.degree(copurchaseGraph)
for asin in networkx.nodes(copurchaseGraph):
    metadata = amazonBooks[asin]
    metadata['DegreeCentrality'] = int(dc[asin])
    ego = networkx.ego_graph(copurchaseGraph, asin, radius = 1)
    metadata['ClusteringCoeff'] = round(networkx.average_clustering(ego), 2)
    amazonBooks[asin] = metadata



### Preprocess 6 ###         

fhw = open('./amazon-books.txt', 'w', encoding = 'utf-8', errors = 'ignore')
fhw.write('Id\t' + 'ASIN\t' + 'Title\t'+
         'Categories\t' + 'Group\t' + 'Copurchased\t'+
         'SalesRank\t' + 'TotalReviews\t' + 'AvgRating\t'+
         'DegreeCentrality\t' + 'ClusteringCoeff\n')
for asin, metadata in amazonBooks.items():
    fhw.write(metadata['Id'] + '\t' + 
              asin + '\t' +
              metadata['Title'] + '\t' +
              metadata['Categories'] + '\t' +
              metadata['Group'] + '\t' +
              metadata['Copurchased'] +'\t' + 
              str(metadata['SalesRank']) + '\t' +
              str(metadata['TotalReviews']) + '\t' +
              str(metadata['AvgRating']) + '\t' +
              str(metadata['DegreeCentrality']) + '\t' +
              str(metadata['ClusteringCoeff']) + '\n')
fhw.close()

# write copurchaseGraph to file
#fhw = open('amazon-books-copurchase.edgelist', 'wb')
#networkx.write_weighted_edgelist(copurchaseGraph, fhw)
#fhw.close()

#fhr= open('amazon-books-copurchase.edgelist', 'rb')
#copurchaseGraph = nx.read_weighted_edgelist(fhr)
#fhr.close()

##### Network Analysis #####

def degree_rank(net):
    degree_sequence = sorted((d for n, d in net.degree()), reverse=True)
    df = pd.DataFrame(degree_sequence, columns = ['Degree'])
    fig = px.scatter(df, y = 'Degree')
    fig.update_layout(xaxis_title="Rank")
    return fig
#degree_rank(copurchaseGraph)


def degree_hist(net, kind = None, group = False):
    if kind == 'in':  degrees = net.in_degree()
    elif kind == 'out':  degrees = net.out_degree()
    else: degrees = net.degree()
    df = pd.DataFrame(degrees, columns = ['Node', 'Degree'])
    nbins = None if group else len(degrees)
    fig = px.histogram(df, x="Degree", nbins = nbins )
    fig.update_layout(yaxis_title="# of Nodes", bargap=0.01)
    return fig 
#degree_hist(copurchaseGraph)


# check connection
nx.is_connected(copurchaseGraph)


# avg degree
sum(dict(copurchaseGraph.degree()).values()) / nx.number_of_nodes(copurchaseGraph)


# number of connected components
nx.number_connected_components(copurchaseGraph)


# Average clustering coefficient
nx.average_clustering(copurchaseGraph)


# The density tells us how many of the possible edges in the graph are actually present:
nx.density(copurchaseGraph)


# Number of triangles
sum(nx.triangles(copurchaseGraph).values()) / 3


deg_cen_g_copurchase = nx.degree_centrality(copurchaseGraph)
sorted_deg_cen_g_copurchase = sorted(deg_cen_g_copurchase.items(), key=lambda x:x[1], reverse = True)[0:50]
ASIN = [i for i,j in sorted_deg_cen_g_copurchase]
degree = [j for i,j in sorted_deg_cen_g_copurchase]
custom_palette1 = sns.color_palette("rocket", 50)
custom_palette2 = sns.color_palette("light:b", 50)
custom_palette2.reverse()
sns.set(rc={'figure.figsize':(15,10), 'axes.facecolor':'white'})
ax = sns.barplot(x = ASIN, y = degree, palette = custom_palette1)
ax = ax.set_xticklabels(ax.get_xticklabels(), rotation = 45)

#list(copurchaseGraph.adj['0890420254'])
#list(copurchaseGraph.edges(data=True))[:1000]
copurchaseGraph.adj['0890420254']

node = 0
for i in list(copurchaseGraph.edges(data=True)):
    if i[0] == '0890420254':
        neigh = purchaseGraph.adj['0890420254']
        
neigh = copurchaseGraph.edges('0890420254', data= True)

weight =[ ]
for i in neigh:
    weight.append(i[2]['weight'])
weight
np.mean(weight)
  
mean_weights = []
for j in ASIN:
    neigh = copurchaseGraph.edges(j, data= True)
    weight = []
    for i in neigh:
        weight.append(i[2]['weight'])
    weight
    mean_weights.append(np.mean(weight))
mean_weights  
print('Mean of similarity between most connected nodes: ', np.mean(mean_weights))

l = list(copurchaseGraph.edges(data= True))
total_weights = []
for i in l:
    total_weights.append(i[2]['weight'])
total_mean_weights = np.mean(total_weights)
print('Mean of similarity between all nodes: ', total_mean_weights)
